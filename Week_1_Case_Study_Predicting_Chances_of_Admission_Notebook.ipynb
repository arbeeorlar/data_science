{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/arbeeorlar/data_science/blob/main/Week_1_Case_Study_Predicting_Chances_of_Admission_Notebook.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IIfOydFLJIaI"
      },
      "source": [
        "# **Predicting Chances of Admission**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Context**"
      ],
      "metadata": {
        "id": "KEWCXoWXrrHl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The world is developing rapidly and continuously looking for the best knowledge and experience among people. This motivates people all around the world to stand out in their jobs and look for higher degrees that can help them in improving their skills and knowledge. As a result, the number of students applying for Master's programs has increased substantially.\n",
        "\n",
        "The current admission dataset was created for the prediction of admissions into the University of California, Los Angeles (UCLA). It was built to help students in shortlisting universities based on their profiles. The predicted output gives them a fair idea about their chances of getting accepted."
      ],
      "metadata": {
        "id": "NKltCUOKrtxk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Objective**"
      ],
      "metadata": {
        "id": "m_UcxKpZrpE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We need to build a classification model using neural networks to predict a student's chances of admission into UCLA."
      ],
      "metadata": {
        "id": "av1StTtyrwV2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Dictionary**"
      ],
      "metadata": {
        "id": "tSfGMyhZrm1N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dataset contains several features which are considered important during the application for Masters Programs.\n",
        "The features included are:\n",
        "\n",
        "- **GRE Scores:** (out of 340)\n",
        "\n",
        "- **TOEFL Scores:** (out of 120)\n",
        "\n",
        "- **University Rating:**  It indicates the Bachelor University ranking (out of 5)\n",
        "\n",
        "- **Statement of Purpose Strength:** (out of 5)\n",
        "\n",
        "- **Letter of Recommendation Strength:** (out of 5)\n",
        "\n",
        "- **Undergraduate GPA:** (out of 10)\n",
        "\n",
        "- **Research Experience:** (either 0 or 1)\n",
        "\n",
        "- **Chance of Admit:** (ranging from 0 to 1)"
      ],
      "metadata": {
        "id": "YDRz0kG5ryYQ"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUNw9Lh-mZHQ"
      },
      "source": [
        "## **Installing and Importing the necessary libraries**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Installing the libraries with the specified version\n",
        "!pip install --no-deps tensorflow==2.18.0 scikit-learn==1.3.2 matplotlib===3.8.3 seaborn==0.13.2 numpy==1.26.4 pandas==2.2.2 -q --user --no-warn-script-location"
      ],
      "metadata": {
        "id": "1rXu9wOGq8xG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6955d73e-fed0-4da8-80f2-b81cf0dcdd7e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m615.5/615.5 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/10.8 MB\u001b[0m \u001b[31m94.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m102.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m84.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note**:\n",
        "- After running the above cell, kindly restart the runtime (for Google Colab) or notebook kernel (for Jupyter Notebook), and run all cells sequentially from the next cell.\n",
        "- On executing the above line of code, you might see a warning regarding package dependencies. This error message can be ignored as the above code ensures that all necessary libraries and their dependencies are maintained to successfully execute the code in ***this notebook***."
      ],
      "metadata": {
        "id": "E4-hmm7PlfYB"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CK_nbUDBmX2E"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Loading the Data**"
      ],
      "metadata": {
        "id": "54ogEcPxrDQf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# uncomment and run the below code snippets if the dataset is present in the Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "tJr-VdnssAgA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e24fdf3-540d-4b2d-a8bc-f8f05a7adc3e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "cF6d_Z6B2CpB"
      },
      "outputs": [],
      "source": [
        "# Importing the dataset\n",
        "data = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/datasets/ANN/Admission_Predict.csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Overview**"
      ],
      "metadata": {
        "id": "U-t3oxsrrQw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check the top five records of the data\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "sXKw7g69rU5O",
        "outputId": "8c8196ab-a7f6-439b-be4c-ca4373a45dcf"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Serial No.  GRE Score  TOEFL Score  University Rating  SOP  LOR   CGPA  \\\n",
              "0           1        337          118                  4  4.5   4.5  9.65   \n",
              "1           2        324          107                  4  4.0   4.5  8.87   \n",
              "2           3        316          104                  3  3.0   3.5  8.00   \n",
              "3           4        322          110                  3  3.5   2.5  8.67   \n",
              "4           5        314          103                  2  2.0   3.0  8.21   \n",
              "\n",
              "   Research  Chance of Admit   \n",
              "0         1              0.92  \n",
              "1         1              0.76  \n",
              "2         1              0.72  \n",
              "3         1              0.80  \n",
              "4         0              0.65  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e70a4e41-efad-453e-8dc1-427c43ecaa81\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Serial No.</th>\n",
              "      <th>GRE Score</th>\n",
              "      <th>TOEFL Score</th>\n",
              "      <th>University Rating</th>\n",
              "      <th>SOP</th>\n",
              "      <th>LOR</th>\n",
              "      <th>CGPA</th>\n",
              "      <th>Research</th>\n",
              "      <th>Chance of Admit</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>337</td>\n",
              "      <td>118</td>\n",
              "      <td>4</td>\n",
              "      <td>4.5</td>\n",
              "      <td>4.5</td>\n",
              "      <td>9.65</td>\n",
              "      <td>1</td>\n",
              "      <td>0.92</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>324</td>\n",
              "      <td>107</td>\n",
              "      <td>4</td>\n",
              "      <td>4.0</td>\n",
              "      <td>4.5</td>\n",
              "      <td>8.87</td>\n",
              "      <td>1</td>\n",
              "      <td>0.76</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>316</td>\n",
              "      <td>104</td>\n",
              "      <td>3</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.5</td>\n",
              "      <td>8.00</td>\n",
              "      <td>1</td>\n",
              "      <td>0.72</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4</td>\n",
              "      <td>322</td>\n",
              "      <td>110</td>\n",
              "      <td>3</td>\n",
              "      <td>3.5</td>\n",
              "      <td>2.5</td>\n",
              "      <td>8.67</td>\n",
              "      <td>1</td>\n",
              "      <td>0.80</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>314</td>\n",
              "      <td>103</td>\n",
              "      <td>2</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>8.21</td>\n",
              "      <td>0</td>\n",
              "      <td>0.65</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e70a4e41-efad-453e-8dc1-427c43ecaa81')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-e70a4e41-efad-453e-8dc1-427c43ecaa81 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-e70a4e41-efad-453e-8dc1-427c43ecaa81');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-9696ffef-a052-4d24-a15f-a9ac33e8728f\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-9696ffef-a052-4d24-a15f-a9ac33e8728f')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-9696ffef-a052-4d24-a15f-a9ac33e8728f button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 500,\n  \"fields\": [\n    {\n      \"column\": \"Serial No.\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 144,\n        \"min\": 1,\n        \"max\": 500,\n        \"num_unique_values\": 500,\n        \"samples\": [\n          362,\n          74,\n          375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"GRE Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 290,\n        \"max\": 340,\n        \"num_unique_values\": 49,\n        \"samples\": [\n          307,\n          335,\n          297\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"TOEFL Score\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 6,\n        \"min\": 92,\n        \"max\": 120,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          94,\n          119,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"University Rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1,\n        \"min\": 1,\n        \"max\": 5,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          3,\n          1,\n          2\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SOP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9910036207566069,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          1.0,\n          4.0,\n          5.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"LOR \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.9254495738978181,\n        \"min\": 1.0,\n        \"max\": 5.0,\n        \"num_unique_values\": 9,\n        \"samples\": [\n          5.0,\n          3.5,\n          1.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"CGPA\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.6048128003332052,\n        \"min\": 6.8,\n        \"max\": 9.92,\n        \"num_unique_values\": 184,\n        \"samples\": [\n          9.6,\n          8.9,\n          8.24\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Research\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Chance of Admit \",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1411404039503023,\n        \"min\": 0.34,\n        \"max\": 0.97,\n        \"num_unique_values\": 61,\n        \"samples\": [\n          0.92,\n          0.9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yVsWWzVw2brU"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "- In the above dataset, the target variable is **Chance of Admit**.\n",
        "- To make this a classification task, let's convert the target variable into a categorical variable by using a threshold of 80%.\n",
        "- We are assuming that if **Chance of Admit** is more than 80% then **Admit** would be 1 (i.e. yes), otherwise, it would be 0 (i.e. no)."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Data Preprocessing**"
      ],
      "metadata": {
        "id": "JzPviEvfrYo4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HLxtOrbw2ZLS"
      },
      "outputs": [],
      "source": [
        "# Converting the target variable into a categorical variable\n",
        "\n",
        "data['Admit'] = data['Chance of Admit '].apply(lambda x: 1 if x > 0.8 else 0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CY4KERF63aAY"
      },
      "source": [
        "Now that we have created a new target variable, we can remove the column - **Chance of Admit** from the dataset. We can also remove the column - **Serial No.** as it would not add any value to our analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XGCid1us3jRJ"
      },
      "outputs": [],
      "source": [
        "# Dropping columns\n",
        "data = data.drop(['Serial No.', 'Chance of Admit '], axis=1)\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **Exploratory Data Analysis**"
      ],
      "metadata": {
        "id": "x5hMhtRugy5K"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VxPbTdpkC-ax"
      },
      "source": [
        "**Let's check the info of the data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5wPX0lb3wRU"
      },
      "outputs": [],
      "source": [
        "# Let's check the info of the data\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cBQS9b56DC2_"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "- There are **500 observations and 8 columns** in the data.\n",
        "- All the columns are of **numeric data** type.\n",
        "- There are **no missing values** in the data."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Summary Statistics**"
      ],
      "metadata": {
        "id": "kd8maHDRg423"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WpdM4iC0DwPJ"
      },
      "outputs": [],
      "source": [
        "# Let's check the summary statistics of the data\n",
        "data.describe().T"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dwro2RclD222"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "- The average GRE score of students applying for UCLA is ~316 out of 340. Some students scored full marks on GRE.\n",
        "-  The average TOEFL score of students applying for UCLA is ~107 out of 120. Some students scored full marks on TOEFL.\n",
        "- There are students with all kinds of ratings for bachelor's University, SOP, and LOR - ratings ranging from 1 to 5.\n",
        "-  The average CGPA of students applying for UCLA is 8.57.\n",
        "- Majority of students (~56%) have research experience.\n",
        "- As per our assumption, on average 28.4% of students would get admission to UCLA."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhotGVGD4hgT"
      },
      "source": [
        "### **Let's visualize the dataset to see some patterns**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwTqs3205Zk6"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(15,8))\n",
        "sns.scatterplot(data=data,\n",
        "           x='GRE Score',\n",
        "           y='TOEFL Score',\n",
        "           hue='Admit',\n",
        "           size='SOP');"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "csxwJUu4Kmj4"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "- There is a linear relationship between GRE and TOEFL scores. This implies that students scoring high one of them would score high in the other as well.\n",
        "- With the increase in GRE and TOEFL scores, the strength of SOP increases.\n",
        "- We can see a distinction between students who were admitted (denoted by orange) vs those who were not admitted (denoted by blue). We can see that majority of students who were admitted have GRE score greater than 320, TOEFL score greater than 105, and SOP of 4 or higher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cEOrIzXp4m4L"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(10,7))\n",
        "sns.boxplot(data=data,\n",
        "             x='University Rating',\n",
        "             y='CGPA',\n",
        "             hue='Admit')\n",
        "plt.title('Relationship between different University Rating and CGPA')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qphs_7DPMb05"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "- We can see that, with increasing university ratings, the CGPA is also increasing, and also the chances of getting admitted to UCLA have increased.\n",
        "- The CGPA of students getting admission to UCLA is higher as compared to students not getting admission to UCLA which makes sense."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZP_r2sD7B0P"
      },
      "source": [
        "## **Data Preparation**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5N2uA8r4MwX6"
      },
      "source": [
        "This dataset contains both numerical and categorical variables. We need to treat them first before we pass them onto the neural network. We will perform the below pre-processing steps:\n",
        "*   One hot encoding of categorical variables\n",
        "*   Scaling numerical variables\n",
        "\n",
        "An important point to remember: Before we scale numerical variables, we would first split the dataset into train and test datasets and perform scaling separately. Otherwise, we would be leaking information from the test data to the train data and the resulting model might give a false sense of good performance. This is known as **data leakage** which we would like to avoid."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3O6DOWXOWkn"
      },
      "source": [
        "Now, let's split the dataset into train and test datasets. To do that, we would be extracting all the **independent variables** and save them into a variable **features**. And the target variable **Admit** would be saved into a variable **target**. These two variables will be used to split the parent dataset into train and test datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7MQ2juQB8IuT"
      },
      "outputs": [],
      "source": [
        "features = data.drop(['Admit'], axis=1)\n",
        "\n",
        "target = data['Admit']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuYQ0t2WcBLG"
      },
      "source": [
        "The size of the dataset is small and the Keras implementation provides an argument for selecting some percentage of training data as validation data to check the accuracy of the model. Therefore, we will split the data into an 80:20 ratio."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8fE8aF_7hJY"
      },
      "outputs": [],
      "source": [
        "# Splitting the dataset into train and test data\n",
        "X_train, X_test, y_train, y_test =  train_test_split(features, target, test_size=0.2, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U883DzGZOwpp"
      },
      "source": [
        "Now, we will perform scaling on the numerical variables separately for train and test sets. We will perform **fit** and **transform** on the train data and then only we will perform **transform** on the test data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mVdTFnkb8dfQ"
      },
      "outputs": [],
      "source": [
        "scaler = MinMaxScaler()\n",
        "\n",
        "# Here, we are passing all the features (numerical and categorical), that's okay as min-max scaler will not change values of categorical variables\n",
        "X_train_normalized = scaler.fit_transform(X_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2VLYxAVu953T"
      },
      "outputs": [],
      "source": [
        "X_test_normalized = scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X7VT_t5f9bwR"
      },
      "source": [
        "## **Model Building**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbltijMlPVVP"
      },
      "source": [
        "In neural networks, there are so many hyper-parameters that you can play around with and tune the network to get the best results. Some of them are -\n",
        "\n",
        "\n",
        "\n",
        "1.   Number of hidden layers\n",
        "2.   Number of neurons in each hidden layer\n",
        "3.   Activation functions in hidden layers\n",
        "4.   Optimizers\n",
        "5.   Random initialization of weights and biases\n",
        "6.   Batch size\n",
        "7.   Learning rate\n",
        "8.   Early stopping\n",
        "9.   L1 and L2 Regularization\n",
        "10.  Dropout\n",
        "11.  Momentum\n",
        "\n",
        "and so on..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9YFaopNE_lpw"
      },
      "source": [
        "First, let's set the seed for random number generators in NumPy, Python, and TensorFlow to be able to reproduce the same results everytime we run the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTVs7lmH_hXx"
      },
      "outputs": [],
      "source": [
        "# Fixing the seed for random number generators\n",
        "np.random.seed(42)\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tLsxcmgPQ_cG"
      },
      "source": [
        "**Let's build a feed forward neural network with 2 hidden layers and the output layer.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ytCsjy93BKbK"
      },
      "outputs": [],
      "source": [
        "# We will be adding the layers sequentially\n",
        "model_1 = Sequential()\n",
        "\n",
        "# First hidden layer with 128 neurons and relu activation function, the input shape tuple denotes number of independent variables\n",
        "model_1.add(Dense(128, activation='relu', input_shape=(7,)))\n",
        "\n",
        "# We will be switching 20% of neurons off randomly at each iteration to avoid overfitting\n",
        "model_1.add(Dropout(0.2))\n",
        "\n",
        "# Second hidden layer with 64 neurons and relu activation function\n",
        "model_1.add(Dense(64, activation='relu'))\n",
        "\n",
        "# We will be switching 10% of neurons off randomly at each iteration to avoid overfitting\n",
        "model_1.add(Dropout(0.1))\n",
        "\n",
        "# Output layer with only one neuron and sigmoid as activation function will give the probability of students getting admitted into UCLA\n",
        "model_1.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FvBhQn8ZR_HW"
      },
      "source": [
        "Once we are done with the model architecture, we need to compile the model, where we need to provide the loss function that we want to optimize, the optimization algorithm, and the evaluation metric that we are interested in to evaluate the model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GAP99treSW_4"
      },
      "source": [
        "Since this is a binary classification task, we will be minimizing the **binary_crossentropy** and we can choose one optimizer out of\n",
        "1.   SGD\n",
        "2.   RMSprop\n",
        "3.   Adam\n",
        "4.   Adadelta\n",
        "5.   Adagrad\n",
        "6.   Adamax\n",
        "7.   Nadam\n",
        "8.   Ftrl\n",
        "\n",
        "This is a hyper-parameter. You can play around with these optimizers to check which one performs better with a particular data.\n",
        "\n",
        "For now, let's try **adamax** optimizer with **accuracy** as the metric and see the model's summary."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2REFSaSx9RBi"
      },
      "outputs": [],
      "source": [
        "model_1.compile(loss = 'binary_crossentropy', optimizer='adamax', metrics=['accuracy'])\n",
        "\n",
        "model_1.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C7W9EYZnTP1P"
      },
      "source": [
        "From the above summary, we can see that this architecture will train a total of **9,857** parameters i.e. weights and biases in the network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4N6XAn6mA_BD"
      },
      "source": [
        "### **Training the model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hmZ5ZSIlUSVH"
      },
      "source": [
        "Let's now train the model using the below piece of code. We will keep the 10% of the training data for validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hkeCQ_K99nob"
      },
      "outputs": [],
      "source": [
        "history_1 = model_1.fit(X_train_normalized,\n",
        "                    y_train,\n",
        "                    validation_split=0.1,\n",
        "                    epochs=150,\n",
        "                    verbose=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EFMmpLAuBC4n"
      },
      "source": [
        "### **Plotting Accuracy vs Epoch Curve**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oe8CUImT-8xf"
      },
      "outputs": [],
      "source": [
        "plt.plot(history_1.history['accuracy'])\n",
        "plt.plot(history_1.history['val_accuracy'])\n",
        "plt.title('Accuracy vs Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K8cyNSpIjURF"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "- The training accuracy is fluctuating but overall it is increasing with the increase in the epochs.\n",
        "- The validation accuracy is constant between ~80 to 150 epochs.\n",
        "- The model is giving good accuracy. After 150 epochs, the accuracy of the model on the training data is about 93% and the validation accuracy is 90%.\n",
        "- The validation accuracy is closer to the training accuracy. This indicates that the model is giving a generalized performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e3lV6QFMVqQh"
      },
      "source": [
        "Let's try to increase the model complexity by tuning some of the hyper-parameters mentioned earlier and check if we can improve the model performance. Out of all the options we have, let's try to change the number of hidden layers, the number of neurons in each hidden layer, the activation function in the hidden layer, and the optimizer from **adamax** to **adam**. Also, we have observed that validation accuracy became constant after some epochs, let's try less number of epochs which would also reduce the computation time."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcLYYkZo6PaW"
      },
      "source": [
        "First, we need to clear the previous model's history from the session. In Keras, we need special command to clear the model's history otherwise the previous model history remains in the backend.\n",
        "Also, let's fix the seed again after clearing the backend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_GQu0Mv56_IH"
      },
      "outputs": [],
      "source": [
        "# Clearing backend\n",
        "from tensorflow.keras import backend\n",
        "backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7PIxvVI0LqbV"
      },
      "outputs": [],
      "source": [
        "# Fixing the seed for random number generators\n",
        "np.random.seed(42)\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S23oRyS2XJZW"
      },
      "outputs": [],
      "source": [
        "model_2 = Sequential()\n",
        "model_2.add(Dense(128, activation='tanh', input_shape=(7,)))\n",
        "model_2.add(Dropout(0.1))\n",
        "model_2.add(Dense(64, activation='tanh'))\n",
        "model_2.add(Dropout(0.1))\n",
        "model_2.add(Dense(32, activation='tanh'))\n",
        "model_2.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DT1QFebrV9ZC"
      },
      "outputs": [],
      "source": [
        "model_2.compile(loss = 'binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model_2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d0mHas6KV9f9"
      },
      "outputs": [],
      "source": [
        "history_2 = model_2.fit(X_train_normalized,\n",
        "                    y_train,\n",
        "                    validation_split=0.1,\n",
        "                    epochs=100,\n",
        "                    verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i96cw1viV9om"
      },
      "outputs": [],
      "source": [
        "plt.plot(history_2.history['accuracy'])\n",
        "plt.plot(history_2.history['val_accuracy'])\n",
        "plt.title('Accuracy vs Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iu0UbJjKAi8z"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "- We are able to slightly improve the model performance on the training data but the validation accuracy has increased by 5%.\n",
        "- The validation accuracy is higher than the training accuracy. This might due to the small size of the validation set and the model is able is to correctly classify the data points in the validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TLXYwazvu0jQ"
      },
      "source": [
        "**Let's try to further tune some of the hyper-parameters and check if we can improve the model performance.**\n",
        "\n",
        "We will use learning_rate = 0.001 for the optimizer in the training process and increase the model complexity by further increasing the number of layers, the number of nodes in each layer, and the epochs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N7aNw91z_wgD"
      },
      "outputs": [],
      "source": [
        "# Clearing the backend\n",
        "from tensorflow.keras import backend\n",
        "backend.clear_session()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1HMdf0uSO3uw"
      },
      "outputs": [],
      "source": [
        "# Fixing the seed for random number generators\n",
        "np.random.seed(42)\n",
        "\n",
        "import random\n",
        "random.seed(42)\n",
        "\n",
        "tf.random.set_seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xRpBpRf_vXJO"
      },
      "outputs": [],
      "source": [
        "model_3 = Sequential()\n",
        "model_3.add(Dense(256, activation='tanh', input_shape=(7,)))\n",
        "model_3.add(Dropout(0.1))\n",
        "model_3.add(Dense(128, activation='tanh'))\n",
        "model_3.add(Dropout(0.1))\n",
        "model_3.add(Dense(64, activation='tanh'))\n",
        "model_3.add(Dropout(0.1))\n",
        "model_3.add(Dense(32, activation='tanh'))\n",
        "model_3.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kUFccLDy48t"
      },
      "outputs": [],
      "source": [
        "model_3.compile(loss = 'binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=['accuracy'])\n",
        "model_3.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8LBADqBprJ7J"
      },
      "source": [
        "- Notice that the number of trainable parameters has increased substantially as compared to previous models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OLN7jZWmy_fb"
      },
      "outputs": [],
      "source": [
        "history_3 = model_3.fit(X_train_normalized,\n",
        "                    y_train,\n",
        "                    validation_split=0.1,\n",
        "                    epochs=200,\n",
        "                    verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zBvMtn6VzFDJ"
      },
      "outputs": [],
      "source": [
        "plt.plot(history_3.history['accuracy'])\n",
        "plt.plot(history_3.history['val_accuracy'])\n",
        "plt.title('Accuracy vs Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-xfRck7yrbX5"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "- This model is giving a generalized performance with 94% accuracy on the train data.\n",
        "- One reason for the algorithm not being able to reach higher than 95% even for training data might be due to the optimizer being stuck at some local minima.\n",
        "- One way to resolve that is to further tune the model with some other hyper-parameters.\n",
        "- Among all three models, model 3 has given the best performance. Let's check its performance on the test data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSpvgJ_ZPP0f"
      },
      "source": [
        "### **Model evaluation on the test data**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VNs-4a67SXNT"
      },
      "outputs": [],
      "source": [
        "model_3.evaluate(X_test_normalized, y_test, verbose = 1)\n",
        "test_pred = np.round(model_3.predict(X_test_normalized))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RldGhjVdxHCx"
      },
      "source": [
        "The test accuracy is coming out to be 96% which implies that our model is able to replicate the performance from the train and validation data on the test (unseen) data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y5fWdjHHPTZh"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "print(classification_report(y_test, test_pred))\n",
        "cm = confusion_matrix(y_test, test_pred)\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.heatmap(cm, annot=True,  fmt='.0f',xticklabels=['Not Admitted', 'Admitted'], yticklabels=['Not Admitted', 'Admitted'])\n",
        "plt.ylabel('Actual')\n",
        "plt.xlabel('Predicted')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uk_tuE7LxGC3"
      },
      "source": [
        "**Observations:**\n",
        "\n",
        "- The confusion matrix shows that the model can identify the majority of students who would get admission and who won't get admission to UCLA.\n",
        "- The classification report shows that all the metrics except recall for class 1 are above 90%, which is good."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bVzop-DYYmv"
      },
      "source": [
        "## **Conclusion:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiMgKE2xYbCW"
      },
      "source": [
        "In this case study,\n",
        "- We have learned how to build a feed-forward neural network for a classification task using Keras.\n",
        "- We have seen different hyper-parameters and how they affect the network.\n",
        "- We also learned about the accuracy vs. epoch curve and how it aids in understanding how the model learns weights.\n",
        "- We were able to get the test accuracy of 96% using the final model.\n",
        "- Interested learners can further analyze the misclassified points and see if there is a pattern or if they were outliers that our model could not identify.\n",
        "- We would highly recommend you to play around with the other hyper-parameters and see for yourself how it affects your model."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}